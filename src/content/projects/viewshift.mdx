---
title: "ViewShift: Interactive and Adaptive Rotation Gains in Virtual Reality (VR)"
slug: viewshift
cover: vr-head-movements/vr-head-movements.png
excerpt: "Masterâ€™s thesis project exploring novel head rotation amplification techniques to address limited physical movement in seated VR, enabling more effective 360Â° navigation and interaction."
tags: [XR, VR, HCI, Interaction Design, Unity, Prototyping]
skills: [Research, Prototyping, Unity]
date: 2024-03-01
showOnHome: true
priority: 0
links:
  repo: https://github.com/kiaksarg/vr-head-rotation-amplification
  demo: https://rotationgains.netlify.app
---
<img
  src="/vr-head-movements/vr-head-movements.png"
  alt="Cover image: Head Rotation Amplification"
  className="my-4 w-full max-w-lg mx-auto rounded-xl shadow-md"
/>

<Head>
  <link rel="canonical" href="/projects/viewshift" />
  <title>ViewShift</title>
</Head>


As part of my Master's thesis in Human-Computer Interaction (HCI) at UmeÃ¥ University, supervised by Prof. Anders LundstrÃ¶m,
I explored novel head rotation amplification techniques in Virtual Reality (VR) specifically designed
to overcome the challenges posed by physically restricted turning angles in seated VR environments.
{/* In seated VR, physical rotation is limited, making full 360Â° exploration difficult. Amplifying head movements increases the virtual rotation relative to physical movement, enabling users to explore virtual environments with less physical effort. */}
<div className="font-semibold uppercase tracking-wide mb-0 mt-8">Abstract</div>
<div className="p-2 rounded-md italic text-gray-700 dark:text-gray-300 leading-relaxed">
In seated virtual reality (<em>VR</em>), where large physical turns are limited, 
altering the mapping between physical and virtual movements can amplify head rotation, 
enabling efficient view control with reduced physical effort.
This thesis introduces two amplified head rotation (<em>AHR</em>) techniques for seated VR: 
the user-empowered <strong>Interactive</strong>, which affords user-timed switching 
between high and low gain, and <strong>Adaptive</strong>, which adjusts gain automatically 
based on head-motion kinematics.
We evaluated both techniques in a mixed-methods study (<em>n = 31</em>), compared with a 
<strong>Static</strong> constant-gain baseline (<em>g = 2.5</em>) across a 
<em>head-pointing task</em> and a <em>180Â° rotation task</em>.
Both <strong>Interactive</strong> and <strong>Adaptive</strong> improved head-pointing performance 
relative to <strong>Static</strong>, while increasing physical head movement; 
<em>cybersickness</em> remained low and <em>virtualâ€“physical heading offsets</em> were generally modest.
Qualitatively, participants valued <strong>Interactive</strong> for the agency and control it afforded. 
Notably, this control enabled an emergent behavior in which users intentionally reoriented the virtual view 
via asymmetric rotational gains â€” a user-initiated redirection strategy we term <strong>ViewShift</strong>.
<strong>Adaptive</strong> reduced cognitive load but could occasionally misalign with user intent.
Together, the findings suggest potential for giving users control over <em>rotational gains</em> 
and highlight visible, user-centered <em>AHR</em> as an interaction technique for seated VR.
</div>

<div className="mt-4 flex flex-wrap gap-3">
  <a
    href="/viewshift.pdf"
    target="_blank"
    rel="noopener noreferrer"
    className="px-4 py-2 rounded-lg bg-indigo-600 text-white text-sm font-medium hover:bg-indigo-700 transition"
  >
    ðŸ“„ Read Full Thesis (PDF)
  </a>
  <a
    href="https://umu.diva-portal.org/smash/record.jsf?pid=diva2:2004521"
    target="_blank"
    rel="noopener noreferrer"
    className="px-4 py-2 rounded-lg bg-gray-200 dark:bg-gray-700 text-gray-900 dark:text-gray-100 text-sm font-medium hover:bg-gray-300 dark:hover:bg-gray-600 transition"
  >
    ðŸ”— View on DiVA Portal
  </a>
</div>

## Implemented Prototype in Unity 3D

  <div className="relative pt-[56.25%]">
    <iframe
      className="absolute top-0 left-0 w-full h-full rounded-2xl shadow-lg"
      src="https://www.youtube.com/embed/15Avg0FLA88?vq=hd1080p"
      title="Head Rotation Amplification Demo"
      allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
      allowFullScreen
    />
  </div>


# Techniques

## Static Gain (Baseline)

**Static amplification:** Physical head rotation multiplied by a fixed factor. For example, a 30Â° turn becomes 60Â° in VR (gain = 2).

## Interactive (User-Empowered) Gain

**Interactive amplification:** Gives users direct control over <em>rotational gains</em>, allowing them to manually toggle between high and low gains using VR controllers during ballistic (rapid rotation) and corrective phases for higher accuracy.

## Adaptive Gain

**Adaptive amplification:** Automatically adjusts the rotational gain based on head rotation velocity and acceleration, increasing during rapid (ballistic) movements and returning toward normal gain during slower, corrective movements to support precise alignment.

## ViewShift: Emergent Reorientation Strategy

During the study, several participants discovered they could intentionally reorient the virtual view without torso rotation by alternating between high- and low-gain states in the <strong>Interactive</strong> technique.  
By applying asymmetric gain sequencesâ€”either <em>fast-out/slow-back</em> or <em>slow-out/fast-back</em>â€”participants could intentionally create and exploit a virtualâ€“physical heading offset in a desired direction to reorient the view. 

# Study Design

We conducted a mixed-methods, within-subjects evaluation comparing three rotational gain techniques for seated VR: **Static** (constant gain 2.5Ã—), **Interactive** (user-timed switching), and **Adaptive** (automatic adjustment based on head rotation velocity/acceleration).   
31 participants performed two tasks (head-pointing and 180Â° rotation) under all techniques in randomized order.  

## Metrics Collected
### Objective Measures
<ul className="list-disc list-inside space-y-2 my-4">
  <li className="mb-1"><strong>Task Completion Time</strong>: Time required to complete tasks.</li>
  <li className="mb-1"><strong>Error Rate</strong>: The number of times targets were missed, and the angular deviation from the intended target.</li>
  <li className="mb-1"><strong>Virtualâ€“Physical Heading Offset</strong>:
    The absolute angular difference (in degrees) between a participantâ€™s physical yaw heading at baseline 
    (recorded when selecting the front home target at trial start) and their heading when re-selecting 
    that same target at mid- or end-task checkpoints. This measure captures any lasting 
    virtualâ€“physical misalignment accumulated due to asymmetric rotational gains.</li>
  <li className="mb-1"><strong>Physical Accumulated Head Movement</strong>: 
  Total physical head rotation accumulated during each task.</li>
</ul>

### Subjective Measures
<ul className="list-disc list-inside space-y-2 my-4">
  <li className="mb-1"><strong>NASA-TLX</strong>: Perceived workload across mental, physical, and temporal dimensions.</li>
  <li className="mb-1"><strong>CSQ-VR</strong>: Self-reported cybersickness symptoms before and after each block.</li>
  <li className="mb-1"><strong>Self-designed Usability Questions</strong>: 
    How participants perceived each technique in terms of Control, Comfort, Ease of Use, Precision, Applicability, and Naturalness.</li>
</ul>


## Qualitative Accounts
<div>User feedback was gathered through semi-structured interviews to explore the following areas:</div>
<ul className="list-disc list-inside space-y-2 my-4">
  <li className="mb-1">How users experienced amplified head rotation compared to normal 1:1 mapping.</li>
  <li className="mb-1">How participants experienced each technique in terms of control, sense of agency, precision, naturalness, and acceptance.</li>
  <li className="mb-1">How head rotation amplification affected users' sense of direction and spatial orientation.</li>
  <li className="mb-1">How users perceived, managed, and recovered from virtualâ€“physical heading offsets.</li>
  <li className="mb-1">Preferences between different amplification techniques (interactive vs. adaptive).</li>
</ul>

## Tasks

<figure className="my-8 max-w-xl mx-auto">
  <div className="relative w-full aspect-[16/9]">
    <ZoomImage
      fill
      src="/vr-head-movements/180-task.gif"
      alt="Head Rotation Amplification, 180Â° Rotation Task"
      className="rounded-xl shadow-md"
    />
  </div>
  <figcaption className="text-center text-sm text-gray-500">
    180Â° Rotation Task
  </figcaption>
</figure>

<figure className="my-8 max-w-xl mx-auto">
  <div className="relative w-full aspect-[16/9]">
    <ZoomImage
      fill
      src="/vr-head-movements/90-180-tasks.gif"
      alt="Head Rotation Amplification, Small Bubbles Task (90Â° and 180Â° Conditions)"
      className="rounded-xl shadow-md"
    />
  </div>
  <figcaption className="text-center text-sm text-gray-500">
    Small Bubbles Task (90Â° and 180Â° Conditions)
  </figcaption>
</figure>

{/* # Resources & Further Reading */}

## Links

- <FileText className="inline-block w-5 h-5 mr-2 align-text-bottom text-gray-600 dark:text-gray-300" />**Full Thesis (PDF)**: [/viewshift.pdf](/viewshift.pdf)
- <Link2 className="inline-block w-5 h-5 mr-2 align-text-bottom text-gray-600 dark:text-gray-300" />**DiVA Portal Record**: [umu.diva-portal.org/smash/record.jsf?pid=diva2:2004521](https://umu.diva-portal.org/smash/record.jsf?pid=diva2:2004521)
- <Github className="inline-block w-5 h-5 mr-2 align-text-bottom text-gray-600 dark:text-gray-300" /> **GitHub Repository**: [vr-head-rotation-amplification](https://github.com/kiaksarg/vr-head-rotation-amplification)
- <Link2 className="inline-block w-5 h-5 mr-2 align-text-bottom text-gray-600 dark:text-gray-300" /> **React Prototype**: [rotationgains.netlify.app](https://rotationgains.netlify.app)




## Study Poster
<div className="relative w-full max-w-sm mx-auto aspect-[1/1.414] cursor-zoom-in">
  <ZoomImage
    src="/vr-head-movements/vr-head-movements-poster.png"
    alt="Study Poster: Head Rotation Amplification User Study"
    className="rounded-2xl shadow-lg object-contain"
  />
</div>


